{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting percentage of proper nouns matched \n",
    "def proper_noun_match_percentage(candidate_answer,model_answer):\n",
    "    #pos tagging both answers\n",
    "    candidate_answer_POS=nltk.pos_tag(candidate_answer)\n",
    "    model_answer_POS=nltk.pos_tag(model_answer)\n",
    "    \n",
    "    #function to get proper nouns from an answer\n",
    "    def getting_proper_noun(answer):\n",
    "        proper_nouns=[]\n",
    "        for word in answer:\n",
    "            if (word[1] == 'NNP' or word[1] == 'NNPS'):\n",
    "                proper_nouns.append(word[0])\n",
    "        return proper_nouns\n",
    "    \n",
    "    #calling above defined function to get proper nouns in both candidate and model answer\n",
    "    candidate_answer_proper_nouns = getting_proper_noun(candidate_answer_POS)\n",
    "    model_answer_proper_nouns = getting_proper_noun(model_answer_POS)\n",
    "    \n",
    "    #checking the number of proper nouns in model answer\n",
    "    proper_noun_count = len(model_answer_proper_nouns)\n",
    "    \n",
    "    #variable that will count the number of proper nouns that match\n",
    "    proper_noun_match_count = 0\n",
    "    \n",
    "    #finding the number of proper nouns that match\n",
    "    for word in candidate_answer_proper_nouns:\n",
    "        if word in model_answer_proper_nouns:\n",
    "            proper_noun_match_count += 1\n",
    "    \n",
    "    #calculating percentage of proper nouns that match.\n",
    "    if proper_noun_count != 0:\n",
    "        proper_noun_match_percentage = ( proper_noun_match_count / proper_noun_count) * 100\n",
    "    else:\n",
    "        proper_noun_match_percentage = 100  \n",
    "    return proper_noun_match_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "#calculating percentage of words that match\n",
    "def word_match_percentage(candidate_answer,model_answer):\n",
    "    unmatched_words=[]\n",
    "    matched_words_count=0\n",
    "    \n",
    "    #checks for words that macth and increase matched_words_count by 1. The words that don't match are inserted into unmatched_words list \n",
    "    for word in model_answer:\n",
    "        if word in candidate_answer:\n",
    "            matched_words_count += 1\n",
    "        else:\n",
    "            unmatched_words.append(word)\n",
    "\n",
    "    #find synonyms for unmatched words\n",
    "    unmatched_words_synonyms = []\n",
    "    for word in unmatched_words:\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for l in syn.lemmas():\n",
    "                unmatched_words_synonyms.append(l.name())\n",
    "    \n",
    "    #checking if the synonyms of unmatched words match with words in candidate answer, and if it does increase matched_words_count\n",
    "    for word in candidate_answer:\n",
    "        if word in unmatched_words_synonyms:\n",
    "            matched_words_count += 1\n",
    "            \n",
    "    #finding the precentage of similair words in candidate answer compared to model answer        \n",
    "    model_answer_length = len(model_answer)\n",
    "    word_match_percentage = ( matched_words_count / model_answer_length) * 100\n",
    "    \n",
    "    return word_match_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import bigrams\n",
    "#Bigram similarity\n",
    "def bigram_similarity_percentage(candidate_answer,model_answer):\n",
    "    candidate_answer_bigram_tokenized = []\n",
    "    model_answer_bigram_tokenized = []\n",
    "    \n",
    "    #getting bigrams of both model and candidate answer\n",
    "    candidate_bigram = bigrams(candidate_answer)\n",
    "    model_bigram = bigrams(model_answer)\n",
    "    \n",
    "    for w in candidate_bigram:\n",
    "        candidate_answer_bigram_tokenized.append(w)\n",
    "        \n",
    "    for w in model_bigram:\n",
    "        model_answer_bigram_tokenized.append(w)\n",
    "\n",
    "    \n",
    "    #checking the number of bigrams in model answer\n",
    "    bigrams_count = len(model_answer_bigram_tokenized)\n",
    "    \n",
    "    #variable that will count the number of bigrams that are present in both answers\n",
    "    bigram_similarity_count = 0\n",
    "    \n",
    "    #finding the number of bigrams that match\n",
    "    for bigram in candidate_answer_bigram_tokenized:\n",
    "        if bigram in model_answer_bigram_tokenized:\n",
    "            bigram_similarity_count += 1\n",
    "    \n",
    "    #calculating percentage of bigrams that match\n",
    "    bigram_similarity_percentage = ( bigram_similarity_count / bigrams_count) * 100\n",
    "    \n",
    "    return bigram_similarity_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cosine similarity\n",
    "def cosine_similarity(candidate_answer,model_answer):\n",
    "\n",
    "    # form a list containing keywords of both strings. Basically union of candidate_answer and model_answer  \n",
    "    keywords_union = list(set(candidate_answer) | set(model_answer))\n",
    "    A =[];B =[] \n",
    "    for w in keywords_union: \n",
    "        if w in candidate_answer: A.append(1) # create a vector \n",
    "        else: A.append(0) \n",
    "        if w in model_answer: B.append(1) \n",
    "        else: B.append(0) \n",
    "    c = 0\n",
    "\n",
    "    # cosine formula  \n",
    "    for i in range(len(keywords_union)): \n",
    "            c+= A[i]*B[i] \n",
    "    cosine = c / float((sum(A)*sum(B))**0.5) \n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jaccard similarity\n",
    "def jaccard_similarity(candidate_answer,model_answer):\n",
    "    \n",
    "    #getting intersection of candidate_answer and model_answer\n",
    "    keywords_intersection = list(set(candidate_answer) & set(model_answer)) \n",
    "    \n",
    "    #form a list containing keywords of both strings. Basically union of candidate_answer and model_answer  \n",
    "    keywords_union = list(set(candidate_answer) | set(model_answer))\n",
    "    \n",
    "    return (len(keywords_intersection) / len(keywords_union))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dice similarity\n",
    "def dice_similarity(candidate_answer,model_answer):\n",
    "    \n",
    "    #getting intersection of candidate_answer and model_answer\n",
    "    keywords_intersection = list(set(candidate_answer) & set(model_answer))\n",
    "    \n",
    "    return ((2 * len(keywords_intersection)) / (len(candidate_answer) + len(model_answer)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give your answer!\n"
     ]
    }
   ],
   "source": [
    "#Getting candidate answer through voice input\n",
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Give your answer!\")\n",
    "    audio = r.listen(source)\n",
    "    \n",
    "try:\n",
    "    original_candidate_answer = r.recognize_google(audio) \n",
    "except sr.UnknownValueError:\n",
    "    print(\"Google Speech Recognition could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hertfordshire am one of the home counties on northern England. It am bordered by Bedfordshire and Oxfordshire to the north, Essex to the east, Greater London to the south, and Buckinghamshire to the west'"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_model_answer=\"Hertfordshire is one of the home counties in southern England. It is bordered by Bedfordshire and Cambridgeshire to the north, Essex to the east, Greater London to the south, and Buckinghamshire to the west\"\n",
    "original_candidate_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting all the stopwords in english\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize model and candiadte answer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "model_answer_tokenized = word_tokenize(original_model_answer)\n",
    "candidate_answer_tokenized = word_tokenize(original_candidate_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized candidate answer -> ['Hertfordshire', 'am', 'one', 'of', 'the', 'home', 'counties', 'on', 'northern', 'England', '.', 'It', 'am', 'bordered', 'by', 'Bedfordshire', 'and', 'Oxfordshire', 'to', 'the', 'north', ',', 'Essex', 'to', 'the', 'east', ',', 'Greater', 'London', 'to', 'the', 'south', ',', 'and', 'Buckinghamshire', 'to', 'the', 'west']\n",
      "Tokenized model answer -> ['Hertfordshire', 'is', 'one', 'of', 'the', 'home', 'counties', 'in', 'southern', 'England', '.', 'It', 'is', 'bordered', 'by', 'Bedfordshire', 'and', 'Cambridgeshire', 'to', 'the', 'north', ',', 'Essex', 'to', 'the', 'east', ',', 'Greater', 'London', 'to', 'the', 'south', ',', 'and', 'Buckinghamshire', 'to', 'the', 'west']\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenized candidate answer ->\", candidate_answer_tokenized)\n",
    "print(\"Tokenized model answer ->\", model_answer_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stop words from model and candiadte answer\n",
    "def removing_stopwords(tokenized_answer):\n",
    "    filtered_sentence=[]\n",
    "    for word in tokenized_answer:\n",
    "         if word not in stop_words:\n",
    "                filtered_sentence.append(word)\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate answer without stopwords -> ['Hertfordshire', 'one', 'home', 'counties', 'northern', 'England', '.', 'It', 'bordered', 'Bedfordshire', 'Oxfordshire', 'north', ',', 'Essex', 'east', ',', 'Greater', 'London', 'south', ',', 'Buckinghamshire', 'west']\n",
      "Model answer without stopwords -> ['Hertfordshire', 'one', 'home', 'counties', 'southern', 'England', '.', 'It', 'bordered', 'Bedfordshire', 'Cambridgeshire', 'north', ',', 'Essex', 'east', ',', 'Greater', 'London', 'south', ',', 'Buckinghamshire', 'west']\n"
     ]
    }
   ],
   "source": [
    "#removing stopwords from both model and candidate answer using above created function\n",
    "model_answer=removing_stopwords(model_answer_tokenized)\n",
    "candidate_answer=removing_stopwords(candidate_answer_tokenized)\n",
    "print(\"Candidate answer without stopwords ->\", candidate_answer)\n",
    "print(\"Model answer without stopwords ->\", model_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling functions to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "proper_noun_match = proper_noun_match_percentage(candidate_answer,model_answer)\n",
    "word_match = word_match_percentage(candidate_answer,model_answer)\n",
    "bigram_match = bigram_similarity_percentage(candidate_answer,model_answer) \n",
    "cosine = cosine_similarity(candidate_answer,model_answer)\n",
    "jaccard = jaccard_similarity(candidate_answer,model_answer) \n",
    "dice = dice_similarity(candidate_answer,model_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.5"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proper_noun_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.9090909090909"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.95238095238095"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning different weights to the different methods and calculating total mark\n",
    "#### proper_noun_match_percentage -> 30% of total marks\n",
    "#### word_match_percentage -> 30% of total marks\n",
    "#### bigram_similarity_percentage -> 25% of total marks\n",
    "#### cosine_similarity -> 5% of total marks\n",
    "#### jaccard_similarity -> 5% of total marks\n",
    "#### dice_similarity -> 5% of total marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_mark for each question is given out of 100\n",
    "final_mark = (proper_noun_match * 0.3) + (word_match * 0.3) + (bigram_match * 0.25) + ((cosine + jaccard + dice) * 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.4426406926407"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_mark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grammar Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'e151357845',\n",
       "  'offset': 14,\n",
       "  'length': 2,\n",
       "  'description': {'en': 'Consider using third-person verb forms for singular and mass nouns: \"is\".'},\n",
       "  'bad': 'am',\n",
       "  'better': ['is'],\n",
       "  'type': 'grammar'},\n",
       " {'id': 'e1621268180',\n",
       "  'offset': 66,\n",
       "  'length': 2,\n",
       "  'description': {'en': 'Did you mean \"is\"?'},\n",
       "  'bad': 'am',\n",
       "  'better': ['is'],\n",
       "  'type': 'grammar'},\n",
       " {'id': 'e1427092122',\n",
       "  'offset': 199,\n",
       "  'length': 4,\n",
       "  'description': {'en': 'Please add a punctuation mark at the end of paragraph'},\n",
       "  'bad': 'west',\n",
       "  'better': ['west.', 'west!', 'west?', 'west:', 'west,', 'west;'],\n",
       "  'type': 'grammar'}]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#checking the grammar of the original candidate answer using textgears API.\n",
    "response = requests.get(\"https://api.textgears.com/grammar?text=\"+original_candidate_answer+\"&language=en-GB&key=hRgDhKSuk5zLKmw4\")\n",
    "\n",
    "#grammatical errors present in answer\n",
    "response.json()['response']['errors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting number of identified errors\n",
    "no_of_errors = len(response.json()['response']['errors'])\n",
    "\n",
    "no_of_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List of all the words in the original answer\n",
    "original_candidate_answer_wordlist = original_candidate_answer.split()\n",
    "\n",
    "#number of words in the original answer\n",
    "no_of_words = len(original_candidate_answer_wordlist)\n",
    "\n",
    "no_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.823529411764707"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#percentage of grammatical errors in original candidate answer\n",
    "grammar_error_percentage = ( no_of_errors / no_of_words ) * 100\n",
    "\n",
    "grammar_error_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing grammar error percentage from total marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.61911128087598"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_mark -= grammar_error_percentage\n",
    "\n",
    "final_mark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If final mark is less than zero it is converted to zero\n",
    "if final_mark < 0:\n",
    "    final_mark = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.61911128087598"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
